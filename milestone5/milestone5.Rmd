---
title: 'Milestone #5 - 6'
author: "Niel Schrage"
date: "4/8/2020"
output: bookdown::pdf_document2
bibliography:  
biblio-style: "apalike"
link-citations: false
toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading libraries

library(tidyverse)
library(bookdown)
library(tinytex)
library(gt)
library(gtsummary)
library(stargazer)
library(knitr)


pdf_document2()

```

# Introduction

This project is my attempt at replicating a published paper by a respected academic. Is the final for [Gov 1006](https://www.davidkane.info/files/gov_1006_spring_2020.html), a class that has taught me a seemingly endless amount about data science, R, and life's most pressing questions. All analysis for this paper is available in my repository.^[https://github.com/nschrage/replication_2] The paper I have selected is by [Ryan D. Enos](http://ryandenos.com/) entitled ["What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior."](https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12156) Thank you to Professor Enos for providing easily accessible [replication data](http://dvn.iq.harvard.edu/dvn/dv/ajps) through the [Harvard Dataverse](https://dataverse.harvard.edu/).





* A footnote with your repo url and some verbiage about “All analysis for this paper is available . . .” 

**is this referring to my analysis?** 



# Overview

* A 300 – 500 word overview of your replication paper. What was the question they were trying to answer? What motivated the question? What data did they use? How was the data collected? What analysis did they run? What did they conclude? Are their conclusions robust? 

**this is really where I should start. this is super doable and I have no excuse not to have done this.**

* All data from your paper must be processed and available in your repo. Submit a PDF via Canvas with the following components, all of which must be present in future submissions:

**what does it mean for data to be processed? **

* **6** A clear statement about what aspects of the paper you were able to replicate and which parts, if any, you were not able to replicate.

# Proposed Extension

* **6** 500 words about your proposed extension. You do not have to have done the extension yet. (That comes next week.) But it is time to start thinking about what your contribution to human knowledge will be. You seek admission to the School of Athens. What do you have to offer us?

missing values. 

more recent data (?) -- that could be interesting. 

joining other data sets with what I have (?)

need to just to more research in general about this topic. 

less crazy --> making some new cooler visuals (this is appealing).

use the bayesian stan glm thing to see if I  get different results. 

are the results as strong as he suggests. 


# Milestone #5 Beautiful Graphic


* A beautiful graphic which uses this data. (May be similar to or different from a graphic in the original paper.) Use King et al (2000) for inspiration. This is the portion of the submission which will be graded most harshly. Make sure that you include a thorough caption.

**how to include a caption**





# Appendix

```{r setting up replication, echo = FALSE, message=FALSE}

# setting up global values

# this package is about statistical estimates.
library(ei)
# package helpful for matching treated and control groups with similar covariate
# distributions.
library(MatchIt)
# package for producing simple weighted statistics
library(weights)
# simple bootstrapping -- didn't know this existed.
library(simpleboot)
# helpful statistics package, especially for modeling
library(Zelig)
# package that helps format latex objects side by side 
library(apsrtable)

### master graphic parameters for graphics 
ylims = c(-.35,.1)
ylims.2 = c(-.45,.1)
xlims = c(.5,11)
dists = seq(from = 1000, to = 100, by = -100) ###DELETE THIS LATER
xs = seq(1:length(dists))
ys = seq(from = -.35, to = .1, by = .05)
ys.lab = c('-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')
ys.2 = seq(from = -.45, to = .1, by = .05)
ys.lab.2 = c('-0.45','-0.40','-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')

offsets = .15
text.offsets = .025
cex.axis = .9
cex.N = .7
top.text.adj = c(1.3,1.3) ##offsets on labels to reduce crowding
bottom.text.adj = c(-.15,-.85)
point.size = 2
line.offset = .0175

```

```{r figure 1, echo = FALSE}

# how to display results.

# how to only display graph 1, not the appendix stuff

# need to spend more time going through here and figuring out what does what.
# should I just turn in milestone #5 before milestone #6 or should I just go along and do both at the same time.

##load data

# IMPORTANT --> FOR SOME REASON I NEED TO PUT IN THE FULL FILE PATH IN ORDER FOR THIS TO WORK... DOESN'T THIS MAKE IT HARDER FOR MY WORK TO BE REPLICATED? WHAT SHOULD I DO HERE? AM GOING TO PROCEEDE SO THAT I CAN GET STUFF DOWN.

# ALSO WHY DO THE GRAPHS APPEAR IN SEPARATE PDFS, HOW CAN I GET THEM TO APPEAR WITHIN THIS MARKDOWN DOCUMENT? 

wtreat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.effect.mean.boot.csv') 
wtreat.lower = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.effect.conf.boot.lower.csv') 
wtreat.upper = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.effect.conf.boot.upper.csv') 
Nwtreat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.N.csv')
btreat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.effect.mean.boot.csv') 
btreat.lower = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.effect.conf.boot.lower.csv') 
btreat.upper = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.effect.conf.boot.upper.csv') 
Nbtreat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.N.csv')

##letters for marking graphs, one is not used
use.letters = c('a','b','c','d','e','f','skip','g','h')

##cycle through each line of data, each of which are groups defined by diferent namepcts
for(i in 1:nrow(wtreat)){ ##turning into matrices helps below with segment function
	use.wtreat = as.matrix(wtreat[i,])
	use.wlower = as.matrix(wtreat.lower[i,])
	use.wupper = as.matrix(wtreat.upper[i,])
	use.Nwtreat = as.matrix(Nwtreat[i,])
	
	use.btreat = as.matrix(btreat[i,])
	use.blower = as.matrix(btreat.lower[i,])
	use.bupper = as.matrix(btreat.upper[i,])
	use.Nbtreat = as.matrix(Nbtreat[i,])
	
# how to just get figure_1.pdf to display
# also how to get the pdf to display in my document? 
	
##name graphs
	if(i == 7){
		pdf('Figure_1.pdf')
		}
	else{
		pdf(paste('Figure_A1',use.letters[i],'.pdf',sep=''))
		}			
	par(las = 1)
	par(mar = c(5.1, 4.1, .5, .5))
	plot(xs, use.wtreat,
		ylim = ylims,
		xlim = xlims,
		type = 'n',
		ylab = 'Treatment Effect',
		xlab = 'Treated Group Distance from Projects',
		xaxt = 'n',
		yaxt = 'n.csv')
	abline(h = 0, lty = 2)
	
	###draw lines first because I want them to be covered by points
	####create spaces in lines using the offset (this allows the N to be displayed with the text() function)
	##black lines are offset to the left, white lines to the right	
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets, ##only do it for low N blacks because otherwise lines look funny
		y0 = use.btreat[,1:2], y1 =	use.blower[,1:2])
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets,
		y0 = use.btreat[,1:2] + line.offset, 	y1 =	use.bupper[,1:2])
  ##now the others
	segments(x0= xs[3:10]+offsets, x1 = xs[3:10]+offsets,
		y0 = use.blower[,3:10], 	y1 =	use.bupper[,3:10])
		
	segments(x0= xs-offsets, x1 = xs-offsets, ##bottomlines
		y0 = use.wtreat - line.offset, 	y1 =	use.wlower)
	segments(x0= xs-offsets, x1 = xs-offsets, ##toplines
		y0 = use.wtreat, 	y1 =	use.wupper)

  
  ##points and N descriptions
	points(xs-offsets, use.wtreat,
	       cex = point.size,
	       pch = 21, 
	       bg = 'white',
	       col = 'black')
	text(xs-offsets,use.wtreat,
	     paste('(',use.Nwtreat,')',sep = ''),
	     cex = cex.N,
	     #adj = top.text.adj
	     pos = 1
	    )
	
	points(xs+offsets, use.btreat,
	       pch = 16,
	       cex = point.size)
	text(xs+offsets,use.btreat,
	     paste('(',use.Nbtreat,')',sep = ''),
	     cex = cex.N,
	     #adj = bottom.text.adj
	     pos = 3
	    )
	
	axis(side = 1,
		at = xs,
		label = seq(100,1000,100),
		cex.axis = cex.axis
		)
	axis(side = 2,
		at = ys,
		label = ys.lab,
		cex.axis = cex.axis
		)	

	dev.off()
	}




```

```{r figures 2-3, echo=FALSE}

###########################################
###matched groups################
###Figures 2 and 3 and Appendix Figure A3-A12
###################################

##this cycles thorugh a bunch of dataframes, each of which is needed for a different graph
for(figure in c('white.basic.main','white.demo.main','white.demo.property','white.demo.localrace','blackmain','blackcensus')){
	if(figure == 'white.basic.main'){
		##this group is different than the rest because the second set is not actually a diff in diff, but calling it "diffs" for consistency
		treat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.basic.csv')
		treat.2 = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.basic.property.csv')
		fig.nums = c('A3','A4') ##figure names
		pchs = c(17,17) ##point types
		}
	if(figure == 'white.demo.main'){
		treat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.csv')
		diffs = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.diffs.csv')
		fig.nums = c('2','A5')
		pchs = c(17,22)
		}
	if(figure == 'white.demo.property'){
		treat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.property.csv')
		diffs = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.diffs.property.csv')
		fig.nums = c('A6','A7')	
		pchs = c(17,22)
		}	
	if(figure == 'white.demo.localrace'){
		treat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.localrace.csv')
		diffs = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.diffs.localrace.csv')
		fig.nums = c('A8','A9')			
		pchs = c(17,22)
		}
	if(figure == 'blackmain'){
		treat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.property.csv')
		diffs = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.diffs.property.csv')
		fig.nums = c('3','A12')
		pchs = c(17,21)			
		}
	if(figure == 'blackcensus'){
		treat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.csv')
		diffs = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.diffs.csv')
		fig.nums = c('A10','A11')
		pchs = c(17,21)	
		}


	##define axis for different graphs
	if(figure %in% c('white.basic.main','white.demo.main','blackmain')){
			use.ylims = ylims
			use.ys.lab = ys.lab
			use.ys = ys
		}
	else{
			use.ylims = ylims.2
			use.ys.lab = ys.lab.2
			use.ys = ys.2
		}

	##go through pairs for each pair of dataframe
	for(i in 1:2){
		if(i == 1){ 	
			use.treat = treat$coefficient			
			clower = use.treat-(1.96*treat$stdev)
			cupper = use.treat+(1.96*treat$stdev)
			use.N.treat = treat$N.treatment + treat$N.control
			}			
		if(i == 2 & figure != 'white.basic.main'){	
			use.treat = diffs$mean.diff			
			clower = diffs$low.ci
			cupper = diffs$high.ci
			use.N.treat = diffs$N
			}	
		if(i == 2 & figure == 'white.basic.main'){	##white.basic.main figures have slightly different structure 
			use.treat = treat.2$coefficient			
			clower = use.treat- (1.96*treat.2$stdev)
			cupper = use.treat+(1.96*treat.2$stdev)
			use.N.treat = treat.2$N.treatment + treat.2$N.control
			}
		if(figure %in% c('white.demo.main','blackmain') & i ==1){
				pdf(paste('Figure_',fig.nums[i],'.pdf',sep=''))
				}
		else{	
			pdf(paste('Figure_',fig.nums[i],'.pdf',sep=''))
			}
			par(las = 1)
			par(mar = c(5.1, 4.1, .5, .5))
			plot(xs, use.treat,
				ylim = use.ylims,
				xlim = xlims,
				type = 'n',
				ylab = 'Treatment Effect',
				xlab = 'Treated Group Distance from Projects',
				xaxt = 'n',
				yaxt = 'n')
			abline(h = 0, lty = 2)
				
			segments(x0=xs,x1=xs,
						y0= use.treat+line.offset,y1=cupper)
			segments(x0=xs,x1=xs,
						y0= use.treat,y1=clower)

		### Treatment Effects
			points(xs, use.treat, 
				pch = pchs[i], 
				cex = point.size,
					bg = 'white',
       			col = 'black')
			text(xs,use.treat,
			     paste('(',use.N.treat,')',sep = ''),
			     cex = cex.N,
			     pos = 3
			  )
			axis(side = 1,
					at = xs,
					label = seq(100,1000,100),
					cex.axis = cex.axis
					)
			axis(side = 2,
					at = use.ys,
					label = use.ys.lab,
					cex.axis = cex.axis
					)	
			
			dev.off()
		}
	}	

```

```{r figure 4, echo = FALSE}

##write out regression to latex table

# THIS IS SOMETHING THAT DOESN'T WORK, BUT IT IS SOMETHING THAT I CAN WRITE ABOUT FOR ONE OF THE QUESTIONS ON THE MILESTONE. FOR FIGURE 4, THE TABLE WITH THE REGRESSION WAS UNABLE TO LOAD, UPON FURTHER ANALYSIS, IT LOOKS LIKE THE .RDA FILE DOES NOT EXIST IN THE DATA VERSE FOLDER. TO MAKE SURE, I ALSO CHECKED ONLINE AND THIS WAS ALSO THE CASE, NOT SURE WHY THIS IS OR IF IT STOPS US FROM GETTING SOME OF THE OTHER DATA/FIGURES.

#load('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/out.reg.predictions.rda') ##load saved model
#out.model = apsrtable(out.reg.predictions,
#	coef.names = c( 'Intercept','log(distance)','log(percent of local black population)','2000 turnout'),
#	digits = 3
#	)
#writeLines(out.model,
#	'Table_1.tex')

distdat =  read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/predicted.results.distance.vary.context.csv')
areadat = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/predicted.results.area.vary.context.csv')

##new ylims for these graphs
ylims.predict = c(.6,.75)

datas = list(distdat,areadat)##put data in a list to cycle through
##parameters to be used in graphs below
xs = list(seq(from = 10, to = 2000, by = 10), seq(from = 45000, to = 1004000, by = 4800)/1000)
use.letters = c('a','b')
xlabs = c('Distance from Project','Percent of Local Black Population in Demolished Project')
ylabs = c(expression(Pr(vote[2004])),'')
vlines = list(seq(from = 0, to = 2000, by = 200),seq(from = 0, to = 1000, by = 100))
axis.labs = list(as.character(seq(from = 0, to = 2000, by = 200)),
	as.character(c('0','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%')))

for(i in 1:2){
	colnames(datas[[i]]) = c("mean","sd","50%","2.5%","97.5%") ##saving renames columns, so name back

	pdf(paste('Figure_4',use.letters[i],'.pdf',sep=''))
		par(las = 1)
		par(mar = c(5.1, 4.1, .5, .5))
		plot(xs[[i]],datas[[i]][,'mean'],
			type = 'l',
			xlab = xlabs[i],
			ylab = ylabs[i],
			ylim = ylims.predict,
			xaxt = 'n',
			cex.axis = cex.axis,
			lwd = 4
		)
	##put horizontal and vertical lines on plots
	abline(h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	abline(v = vlines[[i]], 
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	lines(xs[[i]],datas[[i]][,'2.5%'],
			lty = 3,
			lwd = 2.5)
	lines(xs[[i]],datas[[i]][,'97.5%'],
			lty = 3,
			lwd = 2.5)
	axis(side = 1, 
		at = vlines[[i]], 
		labels = axis.labs[[i]],
		cex.axis = cex.axis)
		
		dev.off()
	}

```

```{r figures 5-6, echo = FALSE}

pres.elections = c('dole_pct_ei','bush2000_pct_ei','bush2004_pct_ei','mccain_pct_ei')
obama.elections = c('obama_sen_primary_pct_ei','keyes_pct_ei','obama_pres_primary_pct_ei')

dists = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/distance.vote.differences.csv')
demos = read.csv('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/demolished.vote.differences.csv')


graphs = c('5a','5b','6')

for(i in graphs){

	if(i == '5a'){dat = dists}
	else{dat = demos}
		
	if(i %in% c('5a','5b')){
		xlims = c(.75,4.25)
		ylims = c(-.1,.2)	
		}
	else{
		xlims = c(.75,3.25)
		ylims = c(-.1,.25)
		}

	##recode Keyes to Obama general for presentation purposes
	dat[dat$election == 'keyes_pct_ei','x.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','x.mean']
	dat[dat$election == 'keyes_pct_ei','y.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','y.mean']
	dat[dat$election == 'keyes_pct_ei','diff'] =dat[dat$election == 'keyes_pct_ei','y.mean'] - dat[dat$election == 'keyes_pct_ei','x.mean']
	
		pdf(paste('Figure_',i,'.pdf',sep=''),
		width = 7, height = 8)
		par(las = 1)
		par(mar = c(5.1, 4.1, .5, 1.5))
		plot(seq(1:4),
			rep(1,4),
			ylim = ylims,
			xlim = xlims, 
			type = 'n',
			xaxt = 'n',
			yaxt = 'n',
			xlab = 'Election',
			ylab = ifelse(i == '5b','','Treatment Effect')
			)
		abline(h=0, lty = 2)
		
		if(i %in% c('5a','5b')){
			segments(
				x0= seq(1:4)-offsets, 
				x1 = seq(1:4)-offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4)-offsets,
				dat[dat$group == 'white'&dat$election %in% pres.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			segments(
				x0= seq(1:4)+offsets, 
				x1 = seq(1:4)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4)+offsets,
				dat[dat$group == 'black'&dat$election %in% pres.elections,'diff'],
					pch = 16,
					cex = 2
				)
			axis(side = 1, at = seq(1:4), 
				c('1996','2000','2004','2008'), 
				tick = F,
				cex.axis = cex.axis)		
			}
		else{
			segments(
				x0= seq(1:3)-offsets, 
				x1 = seq(1:3)-offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd'])	
					)
			points(seq(1:3)-offsets,
				dat[dat$group == 'white'&dat$election %in% obama.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			segments(
				x0= seq(1:3)+offsets, 
				x1 = seq(1:3)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd'])	
					)
  			points(seq(1:3)+offsets,
				dat[dat$group == 'black'&dat$election %in% obama.elections,'diff'],
					pch = 16,
					cex = 2
				)
		axis(side = 1, at = seq(1:3), 
					c('2004 \n Senate Primary','2004 \n Senate General','2008 \n President Primary'),
					tick = F,
					cex.axis = cex.axis
					)
		
			}	
		axis(side = 2,
			at = seq(from = -.1, to = .3, by = .05),
			label = c('-0.10','-0.05','0.00','0.05','0.10','0.15','0.20','0.25','0.30'),
			cex.axis = cex.axis
			)			
		dev.off()
	}		

```


* Is it written in Base R or in tidyverse. 

* Do I have to reach out to Prof Enos. 

* An Appendix which include a replication of at least one of the tables from your paper. (It can be a simple summary table.) Also, take a screen shot of the original table and include that image in your Appendix. We want to see how closely your results match the original paper’s.

* **6** As with other aspects of this project, the exact requirements will vary across students, depending on the complexity of your replication paper. If you paper only has 3 or 4 tables, we expect you to replicate it all. If it has 50 tables, we do not expect that. Use your best judgment and talk with us. You must replicate any result which you plan to use as the base of your extension.

**how to include a screenshot in the pdf?**

# Appendix Results [Not Sure How to Organize]

# Bibliography

* A bibliography with at least five references, one of which will be the article you are replicating for your extension. 

gary king paper(s).

this paper, and some of its sources --> need to start thinking about what my replication might be.

findings of the paper or the extensions. 

look up exisiting replications of the papers. 

looking at similar issues --> need to do more background research. 

**what should my other sources be? I have no idea??**

